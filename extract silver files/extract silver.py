import os
import csv

# ========== é…ç½®è·¯å¾„ ==========
corpora_root = "corpora-master"
doc_ids_file = "silver_doc_ids.txt"
output_csv = "all_sentences_tokens_entities_silver.csv"   # è¾“å‡ºçš„æ–°csvæ–‡ä»¶

# ========== è¯»å–éœ€è¦å¤„ç†çš„ doc id ==========
with open(doc_ids_file, "r", encoding="utf-8") as f:
    doc_ids = set(line.strip() for line in f if line.strip())

print(f"âœ… æ‰¾åˆ° {len(doc_ids)} ä¸ªéœ€è¦å¤„ç†çš„æ–‡æ¡£ï¼")

# ========== å¼€å§‹éå†å¹¶æå– ==========
all_sentences = []  # æ¯ä¸ªå…ƒç´ æ˜¯ï¼ˆtoken_list, entity_listï¼‰

def clean_entity(entity):
    if entity == "O":
        return "O"
    if entity.startswith("("):
        entity = entity[1:]
    if ")" in entity:
        entity = entity.split(")")[0]
    return entity

for dirpath, dirnames, filenames in os.walk(corpora_root):
    for filename in filenames:
        if filename.endswith(".conllu"):
            full_path = os.path.join(dirpath, filename)
            file_id = os.path.splitext(filename)[0]

            if file_id in doc_ids:
                print(f"ğŸ“„ æ­£åœ¨å¤„ç†: {full_path}")

                current_tokens = []
                current_entities = []

                with open(full_path, "r", encoding="utf-8") as f:
                    for line in f:
                        line = line.strip()

                        if line.startswith("# sent_id"):
                            # é‡åˆ°æ–°çš„å¥å­ID
                            if current_tokens:
                                all_sentences.append((current_tokens, current_entities))
                                current_tokens = []
                                current_entities = []
                            continue

                        if not line or line.startswith("#"):
                            continue

                        parts = line.split("\t")
                        if "-" in parts[0]:
                            continue  # è·³è¿‡ multiword token

                        token = parts[1]
                        misc = parts[9]

                        entity = "O"
                        if misc != "_":
                            for item in misc.split("|"):
                                if item.startswith("Entity="):
                                    entity = item.split("=")[1]

                        entity = clean_entity(entity)
                        current_tokens.append(token)
                        current_entities.append(entity)

                    # ä¸€ä¸ªæ–‡ä»¶ç»“æŸåï¼ŒæŠŠæœ€åä¸€å¥è¡¥è¿›å»
                    if current_tokens:
                        all_sentences.append((current_tokens, current_entities))

print(f"\nâœ… å…¨éƒ¨å®Œæˆï¼æå–äº† {len(all_sentences)} ä¸ªå¥å­ï¼")

# ========== ä¿å­˜åˆ° CSV ==========
# ========== ä¿å­˜åˆ° CSV ==========
with open(output_csv, "w", newline='', encoding="utf-8") as f:
    writer = csv.writer(f)
    writer.writerow(["Tokens", "Entities"])  # å†™header

    for tokens, entities in all_sentences:
        token_str = " ".join(tokens)        # tokenç”¨ç©ºæ ¼è¿æˆä¸€å¥
        entity_str = " ".join(entities)      # labelä¹Ÿç”¨ç©ºæ ¼è¿æˆä¸€å¥
        writer.writerow([token_str, entity_str])  # ç”¨é€—å·åˆ†å¼€ä¸¤åˆ—