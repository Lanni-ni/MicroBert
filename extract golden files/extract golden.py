import os
import json
import csv

# ========== é…ç½®è·¯å¾„ ==========
corpora_root = "corpora-master"            # ä½ çš„æœ€é¡¶å±‚ corpora æ–‡ä»¶å¤¹
meta_path = os.path.join(corpora_root, "meta.json")
output_csv = "all_sentences_tokens_entities_golden.csv"   # è¾“å‡º CSV æ–‡ä»¶å

# ========== è¯»å– meta.json è¿‡æ»¤å‡º golden æ–‡æ¡£ ==========
with open(meta_path, "r", encoding="utf-8") as f:
    meta = json.load(f)

golden_doc_ids = {doc_id for doc_id, info in meta.items() if info.get("entities") == "gold"}
print(f"âœ… æ‰¾åˆ° {len(golden_doc_ids)} ä¸ª golden æ–‡æ¡£")

# ========== å¼€å§‹éå†å¹¶æå– ==========
sentences = []     # ä¿å­˜æ¯å¥çš„ tokens
sentence_labels = []  # ä¿å­˜æ¯å¥çš„ labels
tokens = []
entities = []

def clean_entity(entity):
    if entity == "O":
        return "O"
    if entity.startswith("("):
        entity = entity[1:]
    if ")" in entity:
        entity = entity.split(")")[0]
    return entity

for dirpath, dirnames, filenames in os.walk(corpora_root):
    for filename in filenames:
        if filename.endswith(".conllu"):
            full_path = os.path.join(dirpath, filename)
            file_id = os.path.splitext(filename)[0]

            if file_id in golden_doc_ids:
                print(f"ğŸ“„ æ­£åœ¨å¤„ç†: {full_path}")

                with open(full_path, "r", encoding="utf-8") as f:
                    for line in f:
                        line = line.strip()
                        if not line:
                            continue
                        if line.startswith("#"):
                            if line.startswith("# sent_id"):
                                # é‡åˆ°æ–°å¥å­idæ—¶ï¼Œä¿å­˜ä¸Šä¸€ä¸ªå¥å­
                                if tokens:
                                    sentences.append(" ".join(tokens))
                                    sentence_labels.append(" ".join(entities))
                                    tokens = []
                                    entities = []
                            continue

                        parts = line.split("\t")
                        if "-" in parts[0]:
                            continue  # è·³è¿‡ multiword token

                        token = parts[1]
                        misc = parts[9]

                        entity = "O"
                        if misc != "_":
                            for item in misc.split("|"):
                                if item.startswith("Entity="):
                                    entity = item.split("=")[1]

                        entity = clean_entity(entity)
                        tokens.append(token)
                        entities.append(entity)

# æœ€åä¸€è¡Œåˆ«å¿˜äº†åŠ è¿›å»
if tokens:
    sentences.append(" ".join(tokens))
    sentence_labels.append(" ".join(entities))

# ========== ä¿å­˜åˆ° CSV ==========
with open(output_csv, "w", newline='', encoding="utf-8") as f:
    writer = csv.writer(f)
    writer.writerow(["Tokens", "Entities"])
    for toks, ents in zip(sentences, sentence_labels):
        writer.writerow([toks, ents])

print(f"\nâœ… å…¨éƒ¨å®Œæˆï¼æå–äº† {len(sentences)} ä¸ªå¥å­ï¼Œä¿å­˜åˆ° {output_csv}")